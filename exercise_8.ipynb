{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "exercise_8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx06_xU7QSlD",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 8: k-Means Clustering and Neural Gas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6gtXtppQSlG",
        "colab_type": "text"
      },
      "source": [
        "**Note**: Please insert the names of all participating students:\n",
        "1. \n",
        "2. \n",
        "3. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwBHileYQSlL",
        "colab_type": "text"
      },
      "source": [
        "## Preamble\n",
        "The following code downloads and imports all necessary files and modules into the virtual machine of Colab. Please make sure to execute it before solving this exercise. This mandatory preamble will be found on all exercise sheets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot9sj4P3QSlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules:\n",
        "  if os.getcwd() == '/content':\n",
        "    !git clone 'https://github.com/inb-uni-luebeck/cs4405.git'\n",
        "    os.chdir('cs4405')\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from utils import utils_8 as utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBsDtcs0QSlb",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 8.1: k-Means Clustering\n",
        "\n",
        "In many cases, the points in a dataset can be grouped into several clusters of points that lie close together. Each `cluster` can be described by a single representative point, the `centroid` or cluster center. In the first part of this exercise, we will study the k-Means Clustering algorithm, a simple algorithm that learns a representation of clusters.\n",
        "\n",
        "We have $N$ `samples` $\\boldsymbol{x}_{\\mu} \\in \\mathbb{R}^{d}$, $\\mu = 1,\\dots,N$ and want to find $k$ `codebook_vectors` $\\boldsymbol{w}_{i} \\in \\mathbb{R}^d$, $i = 1,\\dots,k$ that represent the clusters in the data. Each data point $\\boldsymbol{x}_{\\mu}$ is assigned to the codebook vector that has the smallest euclidean distance to it. We call the index of this codebook vector $i^{∗}$:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "    i^∗ := \\underset{i}{\\operatorname{argmin}} \\lVert\\boldsymbol{x}_{\\mu} − \\boldsymbol{w}_{i}\\rVert_2.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Here is the pseudocode for the k-Means Clustering algorithm: \n",
        "\n",
        "for $t=1$ to $t_{\\max}$\n",
        "> for $\\mu=$ np.random.permutation$(N)$\n",
        ">> - Find the closest codebook vector $\\boldsymbol{w}_{i^{*}}$ to the data point $\\boldsymbol{x}_{\\mu}$. \n",
        "- Update the codebook vector $\\boldsymbol{w}_{i^{*}}$ with $\\boldsymbol{w}_{i^{*}} = \\boldsymbol{w}_{i^{*}} + \\varepsilon_{t} \\left( \\boldsymbol{x}_{\\mu} − \\boldsymbol{w}_{i^{*}} \\right)$.\n",
        "\n",
        "where $\\varepsilon_t$ is the `learning_rate` that exponentially decays from an `initial_learning_rate` $\\varepsilon_{start}$ to an `end_learning_rate` $\\varepsilon_{end}$ as the number of performed learning `epochs` $t$ increases:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "  \\varepsilon_t = \\varepsilon_{start}\\left(\\frac{\\varepsilon_{end}}{\\varepsilon_{start}}\\right)^{t/t_{max}}.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "**Tasks**:\n",
        "- Implement the k-Means Clustering algorithm in Python \n",
        "- Test your implementation several times varying the `codebook_size` $k$, the `initial_learning_rate` $\\varepsilon_{start}$, and the `end_learning_rate` $\\varepsilon_{end}$\n",
        "\n",
        "**Programming Hints**:\n",
        " - Try to avoid for-loops when computing the distance of `sample` $\\boldsymbol{x}_{\\mu}$ to each `codebook_vector` $\\boldsymbol{w}_{i}$ (`help(np.linalg.norm)`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uA8YSXQQSld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def k_means(samples, codebook_size, n_epochs, \n",
        "            initial_learning_rate, end_learning_rate):\n",
        "  \n",
        "  # n_samples: number of samples / n_features: number of features\n",
        "  n_samples, n_features = samples.shape\n",
        "    \n",
        "  # TODO: randomly initialize codebook_vectors in range [-5, 5]\n",
        "  codebook_vectors = \n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    \n",
        "    # TODO: calculate the current learning rate\n",
        "    learning_rate = \n",
        "\n",
        "    # generate randomly permuted index array\n",
        "    indexes = np.random.permutation(n_samples)\n",
        "        \n",
        "    # iterate through all indexes in the index array\n",
        "    for index in indexes:\n",
        "      \n",
        "      # get current sample\n",
        "      sample = samples[index]\n",
        "\n",
        "      # TODO: calculate the euclidean distances between sample and each codebook vector\n",
        "      distances = \n",
        "\n",
        "      # TODO: get the index of the closest codebook vector to sample\n",
        "      index_min = \n",
        "\n",
        "      # TODO: update the codebook vector\n",
        "      codebook_vectors[index_min, :] = \n",
        "\n",
        "      yield {'codebook_vectors': codebook_vectors}\n",
        "\n",
        "\n",
        "# load the dataset\n",
        "samples = utils.load_data('data/data_8.npz')\n",
        "\n",
        "# TODO: set the k-means parameters\n",
        "codebook_size = \n",
        "n_epochs = \n",
        "initial_learning_rate = \n",
        "end_learning_rate = \n",
        "\n",
        "generator = k_means(samples, codebook_size, n_epochs, \n",
        "                    initial_learning_rate, end_learning_rate)\n",
        "animation = utils.Animation(samples, codebook_size)\n",
        "animation.animate(generator,\n",
        "                  max_frames=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18LjB3bhQSmM",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 8.2: Neural Gas\n",
        "\n",
        "The Neural Gas algorithm is very similar to the above k-Means Clustering algorithm, but for a given `sample` it adapts all`codebook_vectors` in a *soft-competitive* fashion, instead of *hard-competitively* changing only the winner $i^{∗}\\left( \\boldsymbol{x}_{\\mu} \\right)$. \n",
        "\n",
        "For codebook adaptation we use a neighborhood function $\\lambda_t$ that determines how much close-by codebook vectors are attracted by the current `sample` $\\boldsymbol{x}_{\\mu}$. Just like $\\varepsilon_t$, Neural Gas cools the `neighborhood_radius` $\\lambda_t$ down from an `initial_neighborhood_radius` $\\lambda_{start}$ to a `end_neighborhood_radius` $\\lambda_{end}$:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "  \\lambda_t = \\lambda_{start}\\left(\\frac{\\lambda_{end}}{\\lambda_{start}}\\right)^{t/t_{max}}.\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "All $k$ `codebook_vectors` $\\boldsymbol{w}_{i}$ are updated as follows:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "  \\boldsymbol{w}_{i} = \\boldsymbol{w}_{i} + \\varepsilon_t e^{\\frac{-r_{i} \\left( \\boldsymbol{x}_{\\mu} \\right)}{\\lambda_{t}}}(\\boldsymbol{x}_{\\mu} − \\boldsymbol{w}_{i}).\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "where $r_{i} \\left( \\boldsymbol{x}_{\\mu} \\right)$ is the `rank` of `codebook_vector` $\\boldsymbol{w}_{i}$:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "  r_{i} \\left( \\boldsymbol{x}_{\\mu} \\right) = \\lvert \\left\\{ j \\mid  \\lVert \\boldsymbol{x}_{\\mu} − \\boldsymbol{w}_{j} \\rVert_2 < \\lVert \\boldsymbol{x}_{\\mu} − \\boldsymbol{w}_{i} \\rVert_2 \\right\\} \\rvert,\n",
        "\\end{align}\n",
        "$$ \n",
        "\n",
        "i.e. the number of codebook vectors $\\boldsymbol{w}_{j}$ that have a smaller euclidean distance to $\\boldsymbol{x}_{\\mu}$ than $\\boldsymbol{w}_{i}$.\n",
        "\n",
        "**Tasks**:\n",
        "- Implement the Neural Gas algorithm in Python \n",
        "- Test your implementation several times varying the `codebook_size` $k$, the `initial_neighborhood_radius` $\\lambda_{start}$, and the `end_neighborhood_radius` $\\lambda_{end}$\n",
        "\n",
        "**Programming Hints**:\n",
        "- Try to avoid for-loops when updating all codebook vectors. \n",
        "- Note that broadcasting only works for the last dimension of a tensor, therefore you might need to change its shape.\n",
        "\n",
        "**Questions**:\n",
        "- What differences do you notice between representations learned by k-Means Clustering and Neural Gas?\n",
        "\n",
        "**Answers**:\n",
        "- \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muxQ6hLsQSlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def neural_gas(samples, codebook_size, n_epochs, \n",
        "               initial_learning_rate, end_learning_rate, \n",
        "               initial_neighborhood_radius, end_neighborhood_radius):\n",
        "\n",
        "  # n_samples: number of samples / n_features: number of features\n",
        "  n_samples, n_features = samples.shape\n",
        "\n",
        "  # TODO: randomly initialize codebook_vectors in range [-5, 5]\n",
        "  codebook_vectors = \n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    \n",
        "    # TODO: calculate the current learning rate\n",
        "    learning_rate = \n",
        "        \n",
        "    # TODO: calculate the neighborhood radius\n",
        "    neighborhood_radius = \n",
        "\n",
        "    # generate randomly permuted index array\n",
        "    indexes = np.random.permutation(n_samples)\n",
        "        \n",
        "    # iterate through all indexes in the index array\n",
        "    for index in indexes:\n",
        "      \n",
        "      # get current sample\n",
        "      sample = samples[index]\n",
        "\n",
        "      # TODO: calculate the euclidean distances between sample and each codebook vector\n",
        "      distances = \n",
        "\n",
        "      # TODO: compute the rank of each codebook vector\n",
        "      ranks = \n",
        "\n",
        "      # TODO: update all codebook vectors\n",
        "      codebook_vectors = \n",
        "\n",
        "      yield {'codebook_vectors': codebook_vectors}\n",
        "\n",
        "\n",
        "# load the dataset\n",
        "samples = utils.load_data('data/data_8.npz')\n",
        "\n",
        "# TODO: set the neural gas parameters\n",
        "codebook_size = \n",
        "n_epochs = \n",
        "initial_learning_rate = \n",
        "end_learning_rate = \n",
        "initial_neighborhood_radius = \n",
        "end_neighborhood_radius = \n",
        "\n",
        "generator = neural_gas(samples, codebook_size, n_epochs, \n",
        "                       initial_learning_rate, end_learning_rate, \n",
        "                       initial_neighborhood_radius, end_neighborhood_radius)\n",
        "animation = utils.Animation(samples, codebook_size)\n",
        "animation.animate(generator,\n",
        "                  max_frames=100)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}